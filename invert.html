<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
    <style>
      body {
        font-family: 'Courier New', monospace;
        background-color: #1a1a1a;
        color: #00ff00;
        margin: 0;
        padding: 20px;
      }
      
      #tonename {
        text-align: center;
        font-size: 30vmin;
        margin-bottom: 20px;
        color: #ffffff;
      }
      
      .meter-container {
        max-width: 800px;
        margin: 0 auto;
        background-color: #2a2a2a;
        border: 2px solid #00ff00;
        border-radius: 10px;
        padding: 20px;
        box-shadow: 0 0 20px rgba(0, 255, 0, 0.3);
      }
      
      .meter-row {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin: 15px 0;
        padding: 10px;
        background-color: #333;
        border-radius: 5px;
      }
      
      .meter-label {
        font-weight: bold;
        min-width: 120px;
      }
      
      .meter-value {
        font-size: 1.2em;
        color: #00ffff;
        min-width: 100px;
        text-align: right;
      }
      
      .frequency-bar {
        width: 300px;
        height: 20px;
        background-color: #444;
        border-radius: 10px;
        overflow: hidden;
        position: relative;
      }
      
      .frequency-fill {
        height: 100%;
        background: linear-gradient(90deg, #ff0000, #ffff00, #00ff00);
        width: 0%;
        transition: width 0.1s ease;
      }
      
      .status-indicator {
        width: 20px;
        height: 20px;
        border-radius: 50%;
        background-color: #666;
        transition: background-color 0.3s ease;
      }
      
      .status-correct {
        background-color: #00ff00;
        box-shadow: 0 0 10px #00ff00;
      }
      
      .progress-bar {
        width: 200px;
        height: 10px;
        background-color: #444;
        border-radius: 5px;
        overflow: hidden;
      }
      
      .progress-fill {
        height: 100%;
        background-color: #00ff00;
        width: 0%;
        transition: width 0.1s ease;
      }
    </style>
</head>
<body>
    <h1 id="tonename"></h1>
    
    <div class="meter-container">
      <div class="meter-row">
        <span class="meter-label">周波数:</span>
        <span class="meter-value" id="frequency-display">0.0 Hz</span>
        <div class="frequency-bar">
          <div class="frequency-fill" id="frequency-bar"></div>
        </div>
      </div>
      
      <div class="meter-row">
        <span class="meter-label">検出音名:</span>
        <span class="meter-value" id="detected-note">---</span>
        <div class="status-indicator" id="match-indicator"></div>
      </div>
      
      <div class="meter-row">
        <span class="meter-label">目標音名:</span>
        <span class="meter-value" id="target-note">---</span>
        <div class="status-indicator"></div>
      </div>
      
      <div class="meter-row">
        <span class="meter-label">経過時間:</span>
        <span class="meter-value" id="timer-display">0.0 秒</span>
        <div class="progress-bar">
          <div class="progress-fill" id="progress-bar"></div>
        </div>
      </div>
      
      <div class="meter-row">
        <span class="meter-label">状態:</span>
        <span class="meter-value" id="status-display">待機中</span>
        <div class="status-indicator" id="status-indicator"></div>
      </div>
    </div>
    <script>
      const tonenames = "ドダレロミマメソリラチシ"
      
      // 音名と周波数のマッピング（複数オクターブ対応）
      const noteFrequencies = {
        'ド': [130.81, 261.63, 523.25, 1046.50], // C2, C4, C5, C6
        'ダ': [138.59, 277.18, 554.37, 1108.73], // C#2, C#4, C#5, C#6
        'レ': [146.83, 293.66, 587.33, 1174.66], // D2, D4, D5, D6
        'ロ': [155.56, 311.13, 622.25, 1244.51], // D#2, D#4, D#5, D#6
        'ミ': [164.81, 329.63, 659.25, 1318.51], // E2, E4, E5, E6
        'マ': [174.61, 349.23, 698.46, 1396.91], // F2, F4, F5, F6
        'メ': [185.00, 369.99, 739.99, 1479.98], // F#2, F#4, F#5, F#6
        'ソ': [196.00, 392.00, 783.99, 1567.98], // G2, G4, G5, G6
        'リ': [207.65, 415.30, 830.61, 1661.22], // G#2, G#4, G#5, G#6
        'ラ': [220.00, 440.00, 880.00, 1760.00], // A2, A4, A5, A6
        'チ': [233.08, 466.16, 932.33, 1864.66], // A#2, A#4, A#5, A#6
        'シ': [246.94, 493.88, 987.77, 1975.53]  // B2, B4, B5, B6
      }
      
      let audioContext
      let analyser
      let microphone
      let dataArray
      let currentNote = ''
      let correctTime = 0
      let lastTime = 0
      
      function generateNewNote() {
        currentNote = tonenames[Math.floor(Math.random() * tonenames.length)]
        tonename.textContent = currentNote
        document.getElementById('target-note').textContent = currentNote
        correctTime = 0
        updateUI()
      }
      
      function updateUI() {
        const frequencyDisplay = document.getElementById('frequency-display')
        const detectedNoteDisplay = document.getElementById('detected-note')
        const timerDisplay = document.getElementById('timer-display')
        const progressBar = document.getElementById('progress-bar')
        const matchIndicator = document.getElementById('match-indicator')
        const statusDisplay = document.getElementById('status-display')
        const statusIndicator = document.getElementById('status-indicator')
        const frequencyBar = document.getElementById('frequency-bar')
        
        return {
          frequencyDisplay,
          detectedNoteDisplay,
          timerDisplay,
          progressBar,
          matchIndicator,
          statusDisplay,
          statusIndicator,
          frequencyBar
        }
      }
      
      function frequencyToNote(frequency) {
        let minDiff = Infinity
        let closestNote = ''
        
        for (const [note, freqArray] of Object.entries(noteFrequencies)) {
          // 各オクターブの周波数をチェック
          for (const freq of freqArray) {
            const diff = Math.abs(frequency - freq)
            if (diff < minDiff) {
              minDiff = diff
              closestNote = note
            }
          }
        }
        
        // 許容範囲を±30Hzに拡大（高いオクターブに対応）
        return minDiff < 30 ? closestNote : null
      }
      
      function getPitch(dataArray) {
        const sampleRate = audioContext.sampleRate
        const bufferLength = dataArray.length
        
        // 音量レベルをチェック（RMS計算）
        let rms = 0
        for (let i = 0; i < bufferLength; i++) {
          rms += dataArray[i] * dataArray[i]
        }
        rms = Math.sqrt(rms / bufferLength)
        
        // 音量閾値を下げる
        if (rms < 0.001) {
          return 0
        }
        
        // FFTを使用した周波数解析
        const fftSize = bufferLength
        const freqData = new Float32Array(fftSize / 2)
        
        // 簡易FFT（実際にはパワースペクトラム計算）
        for (let k = 1; k < freqData.length; k++) {
          let real = 0
          let imag = 0
          
          for (let n = 0; n < bufferLength; n++) {
            const angle = -2 * Math.PI * k * n / bufferLength
            real += dataArray[n] * Math.cos(angle)
            imag += dataArray[n] * Math.sin(angle)
          }
          
          freqData[k] = Math.sqrt(real * real + imag * imag)
        }
        
        // 人間の声・楽器の範囲を拡張（80Hz-2000Hz）
        const minFreq = 80
        const maxFreq = 2000
        const minBin = Math.floor(minFreq * fftSize / sampleRate)
        const maxBin = Math.floor(maxFreq * fftSize / sampleRate)
        
        // 最大パワーを持つ周波数を見つける
        let maxPower = 0
        let peakBin = 0
        
        for (let i = minBin; i < maxBin && i < freqData.length; i++) {
          if (freqData[i] > maxPower) {
            maxPower = freqData[i]
            peakBin = i
          }
        }
        
        // パワーが十分に強い場合のみ周波数を返す
        if (maxPower > rms * 10 && peakBin > 0) {
          return peakBin * sampleRate / fftSize
        }
        
        return 0
      }
      
      function analyzeAudio() {
        analyser.getFloatTimeDomainData(dataArray)
        
        const frequency = getPitch(dataArray)
        const detectedNote = frequencyToNote(frequency)
        const currentTime = Date.now()
        
        // UI要素を取得
        const ui = updateUI()
        
        // 周波数表示を更新
        ui.frequencyDisplay.textContent = frequency > 0 ? `${frequency.toFixed(1)} Hz` : '0.0 Hz'
        
        // 周波数バーを更新（80Hz-2000Hzの範囲で表示）
        const minFreq = 80
        const maxFreq = 2000
        const freqPercent = Math.min(Math.max((frequency - minFreq) / (maxFreq - minFreq) * 100, 0), 100)
        ui.frequencyBar.style.width = `${freqPercent}%`
        
        // 検出された音名を表示
        ui.detectedNoteDisplay.textContent = detectedNote || '---'
        
        if (detectedNote === currentNote) {
          if (lastTime === 0) {
            lastTime = currentTime
          }
          correctTime = currentTime - lastTime
          
          // マッチ状態のUI更新
          ui.matchIndicator.classList.add('status-correct')
          ui.statusDisplay.textContent = '音程一致'
          ui.statusIndicator.classList.add('status-correct')
          
          // 進捗バーを更新
          const progressPercent = Math.min((correctTime / 3000) * 100, 100)
          ui.progressBar.style.width = `${progressPercent}%`
          
          // タイマー表示を更新
          ui.timerDisplay.textContent = `${(correctTime / 1000).toFixed(1)} 秒`
          
          // 3秒間正確な音程が続いた場合
          if (correctTime >= 3000) {
            generateNewNote()
            lastTime = 0
          }
        } else {
          correctTime = 0
          lastTime = 0
          
          // 非マッチ状態のUI更新
          ui.matchIndicator.classList.remove('status-correct')
          ui.statusDisplay.textContent = detectedNote ? '音程不一致' : '音声検出中'
          ui.statusIndicator.classList.remove('status-correct')
          ui.progressBar.style.width = '0%'
          ui.timerDisplay.textContent = '0.0 秒'
        }
        
        requestAnimationFrame(analyzeAudio)
      }
      
      async function startAudio() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
          audioContext = new AudioContext()
          analyser = audioContext.createAnalyser()
          microphone = audioContext.createMediaStreamSource(stream)
          
          analyser.fftSize = 4096
          const bufferLength = analyser.fftSize
          dataArray = new Float32Array(bufferLength)
          
          microphone.connect(analyser)
          
          generateNewNote()
          analyzeAudio()
        } catch (err) {
          console.error('マイクへのアクセスに失敗しました:', err)
        }
      }
      
      // ページ読み込み時に開始
      window.addEventListener('load', () => {
        // ユーザーの操作が必要な場合があるため、クリックで開始
        document.addEventListener('click', startAudio, { once: true })
        generateNewNote()
      })
    </script>
</body>
</html>
